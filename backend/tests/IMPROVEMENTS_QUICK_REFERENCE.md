# Orchestrator Agent Improvements - Quick Reference

## ðŸ“‹ Plan Documents

1. **Main Plan**: `.cursor/plans/orchestrator_agent_improvements_plan.md`
   - Complete improvement plan with phases, timelines, success criteria
   - Detailed prompt improvements
   - Code improvement specifications
   - Implementation timeline

2. **Test Cases**: `tests/test_detailed_scenarios.py`
   - Comprehensive test scenarios
   - Amount validation tests
   - Tool calling sequence tests
   - Decision logic edge cases
   - Error handling scenarios

3. **Analysis Documents**:
   - `tests/COMPLETE_FLOW_ANALYSIS.md` - Current state analysis
   - `tests/PROMPT_IMPROVEMENTS.md` - Prompt improvement details
   - `tests/TEST_RESULTS_SUMMARY.md` - Test results summary

## ðŸŽ¯ Quick Action Items

### Phase 1: Prompt Improvements (Week 1, Days 1-3)

#### Day 1: Reduce Length & Add Sequence
- [ ] Reduce prompt from 137 â†’ 50 lines
- [ ] Add mandatory tool calling sequence with "MUST CALL" emphasis
- [ ] Test with Scenario 1

#### Day 2: Add Validation & Examples
- [ ] Add amount validation instructions
- [ ] Add 2-3 complete examples
- [ ] Test with all scenarios

#### Day 3: Add Format Requirements
- [ ] Add structured JSON format requirement
- [ ] Add fraud detection guidelines
- [ ] Final testing

### Phase 2: Code Improvements (Week 1, Days 4-5)

#### Day 4: Parsing & Validation
- [ ] Improve JSON parsing robustness
- [ ] Improve tool validation with enforcement
- [ ] Test improvements

#### Day 5: Amount & Confidence
- [ ] Improve amount extraction logic
- [ ] Improve confidence calculation
- [ ] Test improvements

### Phase 3: Test Suite (Week 2)

#### Days 1-3: Create Test Cases
- [ ] Amount validation tests (5 scenarios)
- [ ] Tool calling sequence tests (3 scenarios)
- [ ] Decision logic tests (5 scenarios)

#### Days 4-5: Error & Integration
- [ ] Error handling tests (4 scenarios)
- [ ] Blockchain settlement tests (2 scenarios)
- [ ] Run full test suite

## ðŸ”§ Key Code Changes Needed

### 1. Prompt Update (orchestrator_agent.py:109-147)

**Current**: 137 lines, mentions 4-layer but not explicit  
**New**: ~50 lines with:
- Mandatory sequence (numbered steps)
- Amount validation process
- JSON format requirement
- Examples

### 2. Amount Extraction (New method)

```python
def _extract_amount_from_document_result(self, document_result: Dict[str, Any]) -> Optional[float]:
    """Extract total amount from document extraction result."""
    # Check: total_amount, grand_total, final_total
    # Calculate: digit_liability + customer_liability
    # Return: float or None
```

### 3. Confidence Calculation (New method)

```python
def _calculate_confidence_from_results(self, tool_results: Dict[str, Any], agent_confidence: float) -> float:
    """Calculate confidence based on tool results."""
    # Boost if all tools called
    # Boost if amounts match
    # Reduce if contradictions exist
    # Return: 0.0-1.0
```

### 4. Tool Validation Enhancement

```python
def _validate_and_enforce_tool_calls(self, tool_results: Dict[str, Any], evidence: List[Dict], claim_id: str) -> Dict[str, Any]:
    """Validate tool calls and enforce required tools."""
    # Check required tools
    # Apply confidence penalty if missing
    # Return validation result
```

## ðŸ“Š Success Metrics

| Metric | Current | Target | Measurement |
|--------|---------|--------|-------------|
| Tool Calling Completion | ~33% | 95%+ | Tools called / Required |
| Amount Validation Accuracy | 0% | 100% | Mismatches detected / Total |
| JSON Parsing Success | ~0% | 95%+ | Valid JSON / Total responses |
| Decision Accuracy | ~50% | 90%+ | Correct / Total |
| Confidence Accuracy | Low | High | Correlation with validity |

## ðŸ§ª Test Execution

### Run All Tests
```bash
cd backend
pytest tests/test_pdf_complete_flow.py -v
pytest tests/test_detailed_scenarios.py -v
pytest tests/test_orchestrator_plan_improvements.py -v
```

### Run Specific Scenarios
```bash
# Amount validation
pytest tests/test_detailed_scenarios.py::TestAmountValidationScenarios -v

# Tool calling
pytest tests/test_detailed_scenarios.py::TestToolCallingSequence -v

# Decision logic
pytest tests/test_detailed_scenarios.py::TestDecisionLogicEdgeCases -v
```

### Run with Real PDF
```bash
# Requires GOOGLE_AI_API_KEY
export GOOGLE_AI_API_KEY=your-key
pytest tests/test_pdf_complete_flow.py::TestPDFCompleteFlow::test_scenario_1_matching_amount -v -s
```

## ðŸ“ Prompt Template (New Structure)

```
You are an insurance claim evaluation orchestrator.

**MANDATORY Tool Calling Sequence (DO NOT SKIP):**

STEP 1: Extract Data
- MUST call extract_document_data(claim_id, document_path) for EACH document
- MUST call extract_image_data(claim_id, image_path) for EACH image

STEP 2: Estimate Costs
- MUST call estimate_repair_cost(claim_id, extracted_data, damage_assessment)
- MUST call cross_check_amounts(claim_id, claim_amount, extracted_total, ...)

STEP 3: Validate Claim
- MUST call validate_claim_data(claim_id, claim_amount, extracted_data, ...)

STEP 4: Verify
- MUST call verify_document(claim_id, document_path) if documents exist
- MUST call verify_image(claim_id, image_path) if images exist
- MUST call verify_fraud(claim_id) - ALWAYS REQUIRED

**Amount Validation:**
1. Extract total_amount from extract_document_data result
2. Call cross_check_amounts with claim_amount and extracted_total
3. If difference > 20%: Add to contradictions
4. If difference > 50%: Set fraud_risk >= 0.5

**Output Format (JSON ONLY):**
{
  "decision": "...",
  "confidence": 0.0-1.0,
  "reasoning": "...",
  "tool_results": {...},
  "requested_data": [],
  "human_review_required": bool,
  "review_reasons": [],
  "contradictions": [],
  "fraud_risk": 0.0-1.0
}

**Examples:** [2-3 complete examples]
```

## ðŸš¨ Critical Issues to Fix

1. **Tool Calling Inconsistency** â†’ Add mandatory sequence
2. **Amount Validation** â†’ Add extraction/comparison logic
3. **JSON Format** â†’ Enforce JSON-only output
4. **Missing Tools** â†’ Add validation enforcement
5. **Low Confidence** â†’ Improve calculation logic

## ðŸ“… Timeline Summary

- **Week 1**: Prompt + Code improvements
- **Week 2**: Test suite expansion
- **Week 3**: Refinement & documentation

**Total**: 3 weeks for initial improvements

## âœ… Definition of Done

- [ ] 95%+ tool calling completion rate
- [ ] 100% amount mismatch detection (>20% difference)
- [ ] 95%+ valid JSON responses
- [ ] 90%+ decision accuracy
- [ ] All test scenarios passing
- [ ] Documentation updated

## ðŸ”— Related Files

- **Plan**: `.cursor/plans/orchestrator_agent_improvements_plan.md`
- **Tests**: `tests/test_detailed_scenarios.py`
- **Orchestrator**: `backend/src/agent/adk_agents/orchestrator_agent.py`
- **Tools**: `backend/src/agent/adk_tools.py`
